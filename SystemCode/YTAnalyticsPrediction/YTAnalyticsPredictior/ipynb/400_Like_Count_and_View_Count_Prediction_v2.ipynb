{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zpngBM2rWylB",
        "hqyA2nauW1Zm",
        "BdF813bPXCYt",
        "C7lslsE5XPVv",
        "u7Nicq6aXqZV"
      ],
      "machine_shape": "hm",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. Package Install"
      ],
      "metadata": {
        "id": "zpngBM2rWylB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRHxZwnDUI5N"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import keras\n",
        "import json\n",
        "import math\n",
        "import tensorflow as tf \n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, LSTM, Flatten, TimeDistributed, Conv2D, Dropout, RandomFlip, RandomRotation, RandomZoom, RandomWidth, RandomHeight, RandomContrast\n",
        "from keras.layers import MaxPooling2D, RandomTranslation\n",
        "from tensorflow.keras.layers import RandomBrightness\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "from keras.applications import MobileNetV2\n",
        "#from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "import shutil\n",
        "from keras.utils import plot_model\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Data Loading"
      ],
      "metadata": {
        "id": "hqyA2nauW1Zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.0. File Paths"
      ],
      "metadata": {
        "id": "irhcsBgAXcLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_image_filepath = '/content/gdrive/MyDrive/NUS/ISY5002_project_work/001_input_data/imagefiles/YTBB_images/19_dog/19_dog/'\n",
        "dog_image_filepath = '/content/gdrive/MyDrive/NUS/ISY5002_project_work/001_input_data/imagefiles/YTBB_images/07_cat/07_cat/'\n",
        "sliced_image_filepath = '/content/gdrive/MyDrive/NUS/ISY5002_project_work/001_input_data/imagefiles/YTBB_images/consolidated/'\n",
        "thumbnail_filepath = '/content/gdrive/MyDrive/NUS/ISY5002_project_work/001_input_data/imagefiles/YTBB_thumbnails/'\n",
        "npz_path_base = '/content/gdrive/MyDrive/NUS/ISY5002_project_work/003_output/npz_files_v2/'"
      ],
      "metadata": {
        "id": "ecaykPwgaVEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1. Data Loading (Sliced Video Images)"
      ],
      "metadata": {
        "id": "z1mKqyrtW86M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_width = 240\n",
        "image_height = 180\n",
        "\n",
        "def get_img(img_path, printer=True):\n",
        "  original_img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "  if printer: print (\"original dim:\",original_img.shape)\n",
        "  resized_img = cv2.resize(original_img, (image_width, image_height), interpolation=cv2.INTER_AREA) #cv2.INTER_AREA for reduction of width and height\n",
        "  resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB) #Change bgr to rgb\n",
        "  if printer: print (\"resized dim:\", resized_img.shape)\n",
        "  return resized_img\n",
        "#07_cat, 19_dog folder (dog:13,648 files, cat:13,221 files)"
      ],
      "metadata": {
        "id": "8BjCxOw0UjOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Move sliced image files to consolidated folder\n",
        "files_cat = os.listdir(path=cat_image_filepath)\n",
        "print(len(files_cat))\n",
        "files_dog = os.listdir(path=dog_image_filepath)\n",
        "print(len(files_dog))\n",
        "\n",
        "for i in range(len(files_cat)):\n",
        "  path_before_move = cat_image_filepath + files_cat[i]\n",
        "  path_after_move = sliced_image_filepath + files_cat[i]\n",
        "  shutil.move(path_before_move, path_after_move)\n",
        "  print(str(i)+\" / \"+str(len(files_cat))+\" is done\")\n",
        "\n",
        "for i in range(len(files_dog)):\n",
        "  path_before_move = dog_image_filepath + files_dog[i]\n",
        "  path_after_move = sliced_image_filepath + files_dog[i]\n",
        "  shutil.move(path_before_move, path_after_move)\n",
        "  print(str(i)+\" / \"+str(len(files_dog))+\" is done\")"
      ],
      "metadata": {
        "id": "D3vNgve-aJEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check total number of sliced images\n",
        "sliced_image_files = os.listdir(path=sliced_image_filepath)\n",
        "print(len(sliced_image_files)) #26,867 images (out of 26,869 images)"
      ],
      "metadata": {
        "id": "cZe_TelAahXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sliced_image_file_name = pd.DataFrame(sliced_image_files)\n",
        "display_id = pd.DataFrame(pd.Series(sliced_image_files).str[3:14],index=np.arange(0,len(sliced_image_files),1))\n",
        "sliced_image_file_path = pd.DataFrame(sliced_image_filepath + pd.Series(sliced_image_files))\n",
        "sliced_image_file_df = pd.concat([sliced_image_file_name, display_id, sliced_image_file_path], axis=1)\n",
        "sliced_image_file_df.columns = ['sliced_image_file_name','display_id', 'sliced_image_file_path']"
      ],
      "metadata": {
        "id": "766JEkEMj5y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sliced_image_file_df.to_csv('/content/gdrive/MyDrive/NUS/ISY5002_project_work/001_input_data/imagefiles/sliced_image_file_df.csv')"
      ],
      "metadata": {
        "id": "hOHjYFjSkAf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sliced_image_files[0:5]"
      ],
      "metadata": {
        "id": "gX77yr9Ab6dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_img = get_img(sliced_image_filepath+sliced_image_files[5])\n",
        "plt.imshow(resized_img)"
      ],
      "metadata": {
        "id": "8D8qvHn9aB0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2. Data Loading (Thubmnail Files)"
      ],
      "metadata": {
        "id": "BdF813bPXCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Consolidate information regarding thumbnail files\n",
        "thumbnail_file_name = pd.Series(os.listdir('/content/gdrive/MyDrive/NUS/ISY5002_project_work/001_input_data/imagefiles/YTBB_thumbnails'))\n",
        "display_id = pd.DataFrame(thumbnail_file_name.str[0:11],index=np.arange(0,len(thumbnail_file_name),1))\n",
        "thumbnail_file_path = pd.DataFrame(thumbnail_filepath + '/' + thumbnail_file_name)\n",
        "\n",
        "thumbnail_file_df = pd.DataFrame(list(thumbnail_file_name),index=np.arange(0,len(thumbnail_file_name),1))\n",
        "thumbnail_file_df = pd.concat([thumbnail_file_df, display_id, thumbnail_file_path],axis=1)\n",
        "thumbnail_file_df.columns = ['thumbnail_file_name','display_id', 'thumbnail_file_path']\n",
        "thumbnail_file_df #1208 rows"
      ],
      "metadata": {
        "id": "QV9KNMoWhMLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#blank = np.where(np.array(number_of_sliced_images) == 0)[0]\n",
        "#thumbnail_file_df.iloc[blank]\n",
        "#\t3ra5ng0uq9I does not have sliced images\n",
        "\n",
        "#Exclude blank video\n",
        "delete = np.where(np.array(thumbnail_file_df['display_id'] == '3ra5ng0uq9I'))[0][0] #Index of 3ra5ng0uq9I\n",
        "thumbnail_file_df = thumbnail_file_df.drop([delete],axis=0)\n",
        "thumbnail_file_df = thumbnail_file_df.reset_index(drop=True)\n",
        "thumbnail_file_df #1207 rows\n",
        "\n",
        "#Check number of sliced images per video\n",
        "#plt.plot(number_of_sliced_images)\n",
        "#plt.hlines(18,0,1208) #Number of sliced images per video is 18 for almost videos"
      ],
      "metadata": {
        "id": "DqTPjQkPV-F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.3. Data Loading (Metadata)"
      ],
      "metadata": {
        "id": "C7lslsE5XPVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Match meta data with thumbnail file data\n",
        "metadata_df = pd.read_csv('/content/gdrive/MyDrive/NUS/ISY5002_project_work/001_input_data/imagefiles/input_metadata_consolidated.csv',\n",
        "                          index_col=0)\n",
        "metadata_df = metadata_df[['display_id','view_count','like_count','duration','width','height','fps']]\n",
        "metadata_df #1208 rows\n",
        "\n",
        "merged_df = pd.merge(thumbnail_file_df,metadata_df, how=\"inner\", on=\"display_id\")\n",
        "merged_df #1207 rows (by deleting 3ra5ng0uq9I)"
      ],
      "metadata": {
        "id": "pwlNmW-6WJWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Data Consolidation (NPZ file creation)"
      ],
      "metadata": {
        "id": "u7Nicq6aXqZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.1. Choose sliced images per display id (video id)"
      ],
      "metadata": {
        "id": "wciy978iYeUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose sliced images per video id\n",
        "X_check = []\n",
        "number_of_sliced_images = []\n",
        "number_of_sliced_images_per_video = 18\n",
        "\n",
        "for i in range(thumbnail_file_df.shape[0]):\n",
        "  X_sample = []\n",
        "  display_id = thumbnail_file_df['display_id'][i]\n",
        "  selected_sliced_images = np.where(sliced_image_file_df['display_id'] == display_id)[0]\n",
        "  img_paths = sliced_image_file_df.iloc[selected_sliced_images].sort_values(by=\"sliced_image_file_name\")['sliced_image_file_path']\n",
        "  \n",
        "  if len(img_paths) < number_of_sliced_images_per_video:\n",
        "    if len(img_paths) > number_of_sliced_images_per_video-len(img_paths):\n",
        "      addtional_img_paths = img_paths.sample(n=number_of_sliced_images_per_video-len(img_paths), random_state=0, replace=False)\n",
        "      img_paths = pd.concat([img_paths, addtional_img_paths])\n",
        "      img_paths = img_paths.sort_values()\n",
        "    else:\n",
        "      addtional_img_paths = img_paths.sample(n=number_of_sliced_images_per_video-len(img_paths), random_state=0, replace=True)\n",
        "      img_paths = pd.concat([img_paths, addtional_img_paths])\n",
        "      img_paths = img_paths.sort_values()\n",
        "  elif len(img_paths) > number_of_sliced_images_per_video:\n",
        "    img_paths = img_paths.sample(n=number_of_sliced_images_per_video, random_state=0, replace=False)\n",
        "    img_paths = img_paths.sort_values()\n",
        "  \n",
        "  for img_path in img_paths:\n",
        "    resized_img = get_img(img_path, printer=False)\n",
        "    X_sample.append(resized_img)\n",
        "  \n",
        "  number_of_sliced_images.append(len(img_paths))\n",
        "  X_check.append(np.array(X_sample))\n",
        "  print(str(i+1)+\"/\"+str(thumbnail_file_df.shape[0])+\" is done\")"
      ],
      "metadata": {
        "id": "mxWKbJu04-nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Result validation\n",
        "print(pd.DataFrame(number_of_sliced_images).describe())\n",
        "print(np.array(X_check).shape) #1207 videos x 18 slices x 180 height x 240 width x 3 channels"
      ],
      "metadata": {
        "id": "Qpsba5wc9Dp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_check = np.array(merged_df[['view_count','like_count']])\n",
        "y_check.shape #1207 videos x 2 metrics (view_count, like_count)"
      ],
      "metadata": {
        "id": "jA_pJUIMYjf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compress data into npz files\n",
        "npz_paths = []\n",
        "thumnail_width = 224\n",
        "thumnail_height = 224\n",
        "dim = (thumnail_width, thumnail_height)\n",
        "\n",
        "for i,row in merged_df.iterrows():\n",
        "  picture_path = row['thumbnail_file_path']\n",
        "  npz_path = npz_path_base + row['display_id'] + '.npz'\n",
        "  npz_paths.append(npz_path)\n",
        "\n",
        "  pic_bgr_arry = cv2.imread(picture_path)\n",
        "  resized_pic = cv2.resize(pic_bgr_arry, dim, interpolation = cv2.INTER_AREA)\n",
        "  pic_rbg_arry = cv2.cvtColor(resized_pic, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  width, height, fpss, durataion = row['width'], row['height'], row['fps'], row['duration']\n",
        "  stats = np.array([width, height, fpss, durataion])\n",
        "  view_count = row['view_count']\n",
        "  like_count = row['like_count']\n",
        "  sliced_video_images = X_check[i]\n",
        "\n",
        "  #Compress the data\n",
        "  np.savez_compressed(npz_path, pic=pic_rbg_arry, sliced_video_images=sliced_video_images, \n",
        "                      stats=stats, view_count=view_count, like_count=like_count)\n",
        "  print(\"Compressing data into npz files... \"+str(i+1)+\"/\"+str(merged_df.shape[0])+\" is done\")\n",
        "\n",
        "#Need to add 'NPZ_Files' column to merged data\n",
        "merged_df['NPZ_Files'] = pd.Series(npz_paths)\n",
        "merged_df.to_csv('/content/gdrive/MyDrive/NUS/ISY5002_project_work/001_input_data/imagefiles/merged_df_with_npz.csv')"
      ],
      "metadata": {
        "id": "wpqZPWz_ZwQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate the data into train data and test data\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_check, y_check, test_size=0.1)\n",
        "#print(np.array(X_train).shape)\n",
        "#print(np.array(X_test).shape)\n",
        "#print(np.array(y_train).shape)\n",
        "#print(np.array(y_test).shape)"
      ],
      "metadata": {
        "id": "Y4dvZocRhoDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing npz\n",
        "sample_npz = np.load('/content/gdrive/MyDrive/NUS/ISY5002_project_work/003_output/npz_files_v2/-_h-W3_9o0I.npz')\n",
        "print(sample_npz['pic'].shape)\n",
        "print(sample_npz['stats'].shape)\n",
        "print(sample_npz['sliced_video_images'].shape)\n",
        "print(sample_npz['view_count'].shape)\n",
        "print(sample_npz['like_count'].shape)"
      ],
      "metadata": {
        "id": "L12s-eYcxGrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "plt.imshow(sample_npz['pic'])"
      ],
      "metadata": {
        "id": "MP1Eyx_GxTsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(sample_npz['sliced_video_images'][17])"
      ],
      "metadata": {
        "id": "L3pUTOwq1UuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Data Preparation (middle start)"
      ],
      "metadata": {
        "id": "lPATw8Inz_IV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Middle_Start\n",
        "merged_df = pd.read_csv('/content/gdrive/MyDrive/NUS/ISY5002_project_work/001_input_data/imagefiles/merged_df_with_npz.csv',index_col=0) \n",
        "merged_df = merged_df.dropna()\n",
        "merged_df"
      ],
      "metadata": {
        "id": "YOvBMi8-0n-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.drop(['thumbnail_file_name','thumbnail_file_path','duration','width','height','fps'], inplace = True, axis=1)\n",
        "merged_df"
      ],
      "metadata": {
        "id": "ZFPpFmzg0VE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_df = merged_df.sample(frac=1, random_state=0)\n",
        "shuffled_df"
      ],
      "metadata": {
        "id": "2SlVMD8O0bH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df, test_df = shuffled_df[:1000], shuffled_df[1000:1100], shuffled_df[1100:shuffled_df.shape[0]]\n",
        "print(len(train_df),len(val_df),len(test_df))\n",
        "# now the data is ready in these dframes"
      ],
      "metadata": {
        "id": "J8838Zam0gP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to get X_pic, X_stats, and y from a DataFrame\n",
        "def get_X_y(df):\n",
        "  X_pic, X_metadata, X_sliced_video_images = [], [], []\n",
        "  y1 = []\n",
        "  y2 = []\n",
        "  k = 0 #counter\n",
        "  for name in df['NPZ_Files']:\n",
        "    loaded_npz = np.load(name)\n",
        "    pic = loaded_npz['pic']\n",
        "    stats = loaded_npz['stats']\n",
        "    sliced_video_images = loaded_npz['sliced_video_images']\n",
        "    X_pic.append(pic)\n",
        "    X_metadata.append(stats)\n",
        "    X_sliced_video_images.append(sliced_video_images)\n",
        "    y1.append([loaded_npz['like_count']])\n",
        "    y2.append([loaded_npz['view_count']])    \n",
        "    print(k)\n",
        "    k += 1\n",
        "  X_pic, X_metadata, X_sliced_video_images = np.array(X_pic), np.array(X_metadata), np.array(X_sliced_video_images)\n",
        "  y1 = np.array(y1)\n",
        "  y2 = np.array(y2)\n",
        "  return (X_pic, X_metadata, X_sliced_video_images), (y1, y2)"
      ],
      "metadata": {
        "id": "Psz6N_ph0Cp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the data may take 10 mins\n",
        "(X_train_pic, X_train_stats, X_train_sliced_video_images), (y1_train, y2_train) = get_X_y(train_df) #Train data\n",
        "(X_val_pic, X_val_stats, X_val_sliced_video_images), (y1_val, y2_val) = get_X_y(val_df) #Validation data\n",
        "(X_test_pic, X_test_stats, X_test_sliced_video_images), (y1_test, y2_test) = get_X_y(test_df) #Test data"
      ],
      "metadata": {
        "id": "CTWGUDEa0F83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Model Design (1st model to predict like count)"
      ],
      "metadata": {
        "id": "4fpa6jsfwa80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load InceptionResNet V2\n",
        "image_width = 240\n",
        "image_height = 180\n",
        "\n",
        "inceptionresnet=tf.keras.applications.InceptionResNetV2(                                       \n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(image_height,image_width,3)\n",
        ")\n",
        "\n",
        "#Train only the last 4 layers while Freezing the other layers.\n",
        "for layer in inceptionresnet.layers[:-4]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "t-P3v5ohZ3Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1:Thumbnail file tree (deep convolutional network)\n",
        "image_shape=(224,224,3)\n",
        "input_pic = Input(shape=image_shape)\n",
        "#Data augumentation:Filp -> Rotation -> Translation -> Zoom -> Contrast -> Braightness (different order may result in bad results)\n",
        "x1 = RandomFlip(\"horizontal_and_vertical\")(input_pic)\n",
        "x1 = RandomRotation(0.2)(x1)\n",
        "x1 = RandomTranslation(height_factor=0.2, width_factor=0.2)(x1)\n",
        "x1 = RandomZoom(0.3)(x1)\n",
        "x1 = RandomContrast(0.2)(x1)\n",
        "x1 = RandomBrightness([-0.6,0.6])(x1)\n",
        "x1 = Conv2D(64, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(64, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = MaxPooling2D((2,2), strides=(2,2))(x1)\n",
        "x1 = Conv2D(128, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(128, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = MaxPooling2D((2,2), strides=(2,2))(x1)\n",
        "x1 = Conv2D(256, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(256, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(256, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = MaxPooling2D((2,2), strides=(2,2))(x1)\n",
        "x1 = Conv2D(512, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(512, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(512, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = MaxPooling2D((2,2), strides=(2,2))(x1)\n",
        "x1 = Conv2D(512, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(512, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(512, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = MaxPooling2D((2,2), strides=(2,2))(x1)\n",
        "x1 = keras.layers.Flatten()(x1)\n",
        "#fc11=Dense(4096, activation='relu')(fc1)\n",
        "#fc12=Dense(4096, activation='relu')(fc11)\n",
        "#fc13=Dense(2, activation='softmax')(fc12)\n",
        "x1 = Model(inputs=input_pic, outputs=x1)\n",
        "\n",
        "#2:Metadata tree\n",
        "input_stats = layers.Input(shape=(4,))\n",
        "x2 = layers.Dense(64, activation=\"relu\")(input_stats)\n",
        "x2 = layers.Dense(10, activation=\"relu\")(x2)\n",
        "x2 = Model(inputs=input_stats, outputs=x2)\n",
        "\n",
        "#3:Sliced video image tree\n",
        "number_of_sliced_images_per_video = 18\n",
        "image_width = 240\n",
        "image_height = 180\n",
        "\n",
        "input_sliced_images = layers.Input(shape=(number_of_sliced_images_per_video, image_height, image_width, 3))\n",
        "x3 = TimeDistributed(inceptionresnet)(input_sliced_images)\n",
        "x3 = TimeDistributed(Flatten())(x3)\n",
        "x3 = LSTM(256, activation='relu', return_sequences=False)(x3)\n",
        "x3 = layers.Dense(64, activation='relu')(x3)\n",
        "x3 = Dropout(.5)(x3)\n",
        "x3 = layers.Dense(2, activation=\"linear\")(x3)\n",
        "x3 = Model(inputs=input_sliced_images, outputs=x3)\n",
        "\n",
        "#4:Integration layer 1 (#1, #2, #3 to calculate like count)\n",
        "combined = layers.concatenate([x1.output, x2.output, x3.output])\n",
        "y1 = layers.Flatten()(combined)\n",
        "y1 = layers.Dense(1, activation=\"linear\")(y1)\n",
        "#Define the model\n",
        "y1_model = Model(inputs=[x1.input, x2.input, x3.input], outputs=y1)"
      ],
      "metadata": {
        "id": "ADRh0wwdY-7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1_model.summary()"
      ],
      "metadata": {
        "id": "dvnUzYDYkmWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(y1_model, to_file='Cnn + Metadata.png')"
      ],
      "metadata": {
        "id": "dK3pe9RDku6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error','mean_squared_error'])\n",
        "#learning_rate should be small enough. Otherwise, the traning process may not work"
      ],
      "metadata": {
        "id": "HH9hfayna7C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Model Training (1st model to predict like count)"
      ],
      "metadata": {
        "id": "5lgYDa6Dwf2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model saving callback and train for 10 epochs (connect to GPU runtime!!)\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "cp = ModelCheckpoint('model/', save_best_only=True)\n",
        "tf.get_logger().setLevel('ERROR') #do not show warning due to data augumentation\n",
        "r = y1_model.fit(x=[X_train_pic, X_train_stats, X_train_sliced_video_images], y=y1_train, \n",
        "              validation_data=([X_val_pic, X_val_stats, X_val_sliced_video_images], y1_val), epochs=10, callbacks=[cp])"
      ],
      "metadata": {
        "id": "bPoX0CqSc7z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "#from keras.models import load_model\n",
        "#model.save(\"/content/gdrive/MyDrive/NUS/ISY5002_project_work/003_output/CNN+LSTM_models\")"
      ],
      "metadata": {
        "id": "Qh1Ldp-hd8XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loaded_model = load_model(\"/content/gdrive/MyDrive/NUS/ISY5002_project_work/003_output/CNN+LSTM_models\")"
      ],
      "metadata": {
        "id": "zOff_-LTEP8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(r.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(r.history['mean_absolute_error'])\n",
        "#plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(r.history['loss'])\n",
        "plt.plot(r.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "#plt.ylim(0,0.5e9)\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-wwYOA9xeaQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Test Prediction and Result Evaluation  (1st model to predict like count)"
      ],
      "metadata": {
        "id": "aDi5P8giwlDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loaded model to obtain predictions on the test set\n",
        "#(X_test_pic, X_test_stats, X_test_sliced_video_images), y_test = get_X_y(test_df) #Test data\n",
        "#test_predictions = []\n",
        "#number_of_test_samples = X_test_sliced_video_images.shape[0]\n",
        "test_predictions = y1_model.predict([X_test_pic, X_test_stats, X_test_sliced_video_images])\n",
        "\n",
        "#for i in range(number_of_test_samples):\n",
        "# pred = model.predict([X_test_pic[i],X_test_stats[i],X_test_sliced_video_images[i]])\n",
        "#  test_predictions.append(pred)\n",
        "#  print(str(i+1)+\"/\"+str(number_of_test_samples)+\" is done\")"
      ],
      "metadata": {
        "id": "KcaW6IUEEU90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test_pic.shape)\n",
        "print(X_test_stats.shape)\n",
        "print(X_test_sliced_video_images.shape)\n",
        "\n",
        "print(X_test_pic[0].shape)\n",
        "print(X_test_stats[0].shape)\n",
        "print(X_test_sliced_video_images[0].shape)\n",
        "\n",
        "print(type(X_test_pic))\n",
        "print(type(X_test_stats))\n",
        "print(type(X_test_sliced_video_images))"
      ],
      "metadata": {
        "id": "DT3EH8k1uhHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions"
      ],
      "metadata": {
        "id": "Cr5oXKzy2mgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1_test"
      ],
      "metadata": {
        "id": "eFvXYD20OaF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1_test_df = pd.DataFrame(y1_test)\n",
        "test_predictions_df = pd.DataFrame(test_predictions)\n",
        "\n",
        "y1_test_df.columns = ['like_count']\n",
        "test_predictions_df.columns = ['predicted_like_count']\n",
        "\n",
        "test_result = pd.concat([y1_test_df,test_predictions_df],axis=1)\n",
        "test_result = test_result.sort_values(by='like_count',axis=0,ascending=False)"
      ],
      "metadata": {
        "id": "sQLPKR1sKZKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparison with average\n",
        "avg = merged_df['like_count'].mean()\n",
        "plt.ylim(0,300)\n",
        "plt.xlabel(\"Sample (descending order by like count)\")\n",
        "plt.ylabel(\"Like counts\")\n",
        "plt.title(\"Comparison between actual and predicted like count\")\n",
        "plt.hlines(avg,0,test_result.shape[0],color='g',label='average like count in all data')\n",
        "plt.plot(np.arange(0,test_result.shape[0],1),test_result['like_count'],color='b',label='actual like count')\n",
        "plt.plot(np.arange(0,test_result.shape[0],1),test_result['predicted_like_count'],color='r',label='predicted like count')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "-0UY3DomNLTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = merged_df['like_count'].quantile(q=0.25)\n",
        "q2 = merged_df['like_count'].quantile(q=0.5)\n",
        "q3 = merged_df['like_count'].quantile(q=0.75)\n",
        "avg = merged_df['like_count'].mean()\n",
        "\n",
        "like_count_category_avg = []\n",
        "predicted_like_count_category_avg = []\n",
        "avg_category_result = []\n",
        "like_count_category_quantile = []\n",
        "predicted_like_count_category_quantile = []\n",
        "quantile_category_result = []\n",
        "\n",
        "for i in range(test_result.shape[0]):\n",
        "  #View count categorisation by average\n",
        "  if test_result['like_count'][i] > avg: like_count_category_avg.append('above_average')\n",
        "  else: like_count_category_avg.append('below_average')\n",
        "\n",
        "  if test_result['predicted_like_count'][i] > avg: predicted_like_count_category_avg.append('above_average')\n",
        "  else: predicted_like_count_category_avg.append('below_average')\n",
        "\n",
        "  if like_count_category_avg[i] == predicted_like_count_category_avg[i]: avg_category_result.append(True)\n",
        "  else: avg_category_result.append(False)\n",
        "\n",
        "  #View count categorisation by quantile\n",
        "  if test_result['like_count'][i] > q3: like_count_category_quantile.append('1) Top 25%')\n",
        "  elif test_result['like_count'][i] > q2: like_count_category_quantile.append('2) Top 25-50%')\n",
        "  elif test_result['like_count'][i] > q1: like_count_category_quantile.append('3) Lower 25-50%')\n",
        "  else: like_count_category_quantile.append('4) Lowest 25%')\n",
        "\n",
        "  if test_result['predicted_like_count'][i] > q3: predicted_like_count_category_quantile.append('1) Top 25%')\n",
        "  elif test_result['predicted_like_count'][i] > q2: predicted_like_count_category_quantile.append('2) Top 25-50%')\n",
        "  elif test_result['predicted_like_count'][i] > q1: predicted_like_count_category_quantile.append('3) Lower 25-50%')\n",
        "  else: predicted_like_count_category_quantile.append('4) Lowest 25%')\n",
        "\n",
        "  if like_count_category_quantile[i] == predicted_like_count_category_quantile[i]: quantile_category_result.append(True)\n",
        "  else: quantile_category_result.append(False)\n",
        "\n",
        "like_count_category_avg = pd.DataFrame(like_count_category_avg)\n",
        "predicted_like_count_category_avg = pd.DataFrame(predicted_like_count_category_avg)\n",
        "avg_category_result = pd.DataFrame(avg_category_result)\n",
        "like_count_category_quantile = pd.DataFrame(like_count_category_quantile)\n",
        "predicted_like_count_category_quantile = pd.DataFrame(predicted_like_count_category_quantile)\n",
        "quantile_category_result = pd.DataFrame(quantile_category_result)"
      ],
      "metadata": {
        "id": "D_qURPye2mLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(like_count_category_avg.value_counts())\n",
        "print('\\n')\n",
        "print(predicted_like_count_category_avg.value_counts())\n",
        "print('\\n')\n",
        "print(avg_category_result.value_counts())\n",
        "print('\\n')\n",
        "print(like_count_category_quantile.value_counts())\n",
        "print('\\n')\n",
        "print(predicted_like_count_category_quantile.value_counts())\n",
        "print('\\n')\n",
        "print(quantile_category_result.value_counts())"
      ],
      "metadata": {
        "id": "GQBg_3nQ4q24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_result = pd.concat([like_count_category_avg,\n",
        "                             predicted_like_count_category_avg,\n",
        "                             avg_category_result,\n",
        "                             like_count_category_quantile,\n",
        "                             predicted_like_count_category_quantile,\n",
        "                             quantile_category_result],axis=1)\n",
        "category_result.columns = [\"like_count_category_avg\",\n",
        "                           \"predicted_like_count_category_avg\",\n",
        "                           \"avg_category_result\",\n",
        "                           \"like_count_category_quantile\",\n",
        "                           \"predicted_like_count_category_quantile\",\n",
        "                           \"quantile_category_result\"]"
      ],
      "metadata": {
        "id": "IZsBXI7841Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_result"
      ],
      "metadata": {
        "id": "wwjAzYx_48Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix for 2 categories (above_average, below_average)\n",
        "confusion_mat_2cat = category_result.pivot_table('avg_category_result', index='like_count_category_avg',columns='predicted_like_count_category_avg', aggfunc='count')\n",
        "print(confusion_mat_2cat)\n",
        "\n",
        "#metrics calculation\n",
        "accuracy = (confusion_mat_2cat['above_average']['above_average']+confusion_mat_2cat['below_average']['below_average'])/confusion_mat_2cat.sum().sum()\n",
        "recall_above_abv_avg = (confusion_mat_2cat['above_average']['above_average'])/confusion_mat_2cat.loc['above_average'].sum()\n",
        "precision_above_abv_avg = (confusion_mat_2cat['above_average']['above_average'])/confusion_mat_2cat['above_average'].sum()\n",
        "f1_score_abv_avg = 2/(1/recall_above_abv_avg+1/precision_above_abv_avg)\n",
        "\n",
        "recall_above_blw_avg = (confusion_mat_2cat['below_average']['below_average'])/confusion_mat_2cat.loc['below_average'].sum()\n",
        "precision_above_blw_avg = (confusion_mat_2cat['below_average']['below_average'])/confusion_mat_2cat['below_average'].sum()\n",
        "f1_score_blw_avg = 2/(1/recall_above_blw_avg+1/precision_above_blw_avg)\n",
        "\n",
        "#result\n",
        "print('\\n')\n",
        "print(\"Accuracy is \"+str(round(accuracy,2)))\n",
        "print('\\n')\n",
        "print(\"Recall of 'above_average' is \"+str(round(recall_above_abv_avg,2)))\n",
        "print(\"Precision of 'above_average' is \"+str(round(precision_above_abv_avg,2)))\n",
        "print(\"F1 score of 'above_average' is \"+str(round(f1_score_abv_avg,2)))\n",
        "print('\\n')\n",
        "print(\"Recall of 'below_average' is \"+str(round(recall_above_blw_avg,2)))\n",
        "print(\"Precision of 'below_average' is \"+str(round(precision_above_blw_avg,2)))\n",
        "print(\"F1 score of 'below_average' is \"+str(round(f1_score_blw_avg,2)))"
      ],
      "metadata": {
        "id": "-N0desvW4-M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Model Design (2nd model to predict view count)"
      ],
      "metadata": {
        "id": "wEHKKVCevcKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load InceptionResNet V2\n",
        "image_width = 240\n",
        "image_height = 180\n",
        "\n",
        "inceptionresnet=tf.keras.applications.InceptionResNetV2(                                       \n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(image_height,image_width,3)\n",
        ")\n",
        "\n",
        "#Train only the last 4 layers while Freezing the other layers.\n",
        "for layer in inceptionresnet.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "\n",
        "#1:Thumbnail file tree (deep convolutional network)\n",
        "image_shape=(224,224,3)\n",
        "input_pic = Input(shape=image_shape)\n",
        "#Data augumentation:Filp -> Rotation -> Translation -> Zoom -> Contrast -> Braightness (different order may result in bad results)\n",
        "x1 = RandomFlip(\"horizontal_and_vertical\")(input_pic)\n",
        "x1 = RandomRotation(0.2)(x1)\n",
        "x1 = RandomTranslation(height_factor=0.2, width_factor=0.2)(x1)\n",
        "x1 = RandomZoom(0.3)(x1)\n",
        "x1 = RandomContrast(0.2)(x1)\n",
        "x1 = RandomBrightness([-0.6,0.6])(x1)\n",
        "x1 = Conv2D(64, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(64, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = MaxPooling2D((2,2), strides=(2,2))(x1)\n",
        "x1 = Conv2D(128, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(128, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = MaxPooling2D((2,2), strides=(2,2))(x1)\n",
        "x1 = Conv2D(256, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(256, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(256, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = MaxPooling2D((2,2), strides=(2,2))(x1)\n",
        "x1 = Conv2D(512, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(512, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(512, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = MaxPooling2D((2,2), strides=(2,2))(x1)\n",
        "x1 = Conv2D(512, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(512, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(512, (3,3), padding='same', activation='relu')(x1)\n",
        "x1 = MaxPooling2D((2,2), strides=(2,2))(x1)\n",
        "x1 = keras.layers.Flatten()(x1)\n",
        "#fc11=Dense(4096, activation='relu')(fc1)\n",
        "#fc12=Dense(4096, activation='relu')(fc11)\n",
        "#fc13=Dense(2, activation='softmax')(fc12)\n",
        "x1 = Model(inputs=input_pic, outputs=x1)\n",
        "\n",
        "#2:Metadata tree\n",
        "input_stats = layers.Input(shape=(4,))\n",
        "x2 = layers.Dense(64, activation=\"relu\")(input_stats)\n",
        "x2 = layers.Dense(10, activation=\"relu\")(x2)\n",
        "x2 = Model(inputs=input_stats, outputs=x2)\n",
        "\n",
        "#3:Sliced video image tree\n",
        "number_of_sliced_images_per_video = 18\n",
        "image_width = 240\n",
        "image_height = 180\n",
        "\n",
        "input_sliced_images = layers.Input(shape=(number_of_sliced_images_per_video, image_height, image_width, 3))\n",
        "x3 = TimeDistributed(inceptionresnet)(input_sliced_images)\n",
        "x3 = TimeDistributed(Flatten())(x3)\n",
        "x3 = LSTM(256, activation='relu', return_sequences=False)(x3)\n",
        "x3 = layers.Dense(64, activation='relu')(x3)\n",
        "x3 = Dropout(.5)(x3)\n",
        "x3 = layers.Dense(2, activation=\"linear\")(x3)\n",
        "x3 = Model(inputs=input_sliced_images, outputs=x3)\n",
        "\n",
        "#4:Predicted like count\n",
        "predicted_like_count = layers.Input(shape=(1,))\n",
        "x4 = layers.Dense(1, activation='relu')(predicted_like_count)\n",
        "x4 = Model(inputs=predicted_like_count, outputs=x4)\n",
        "\n",
        "#4:Integration layer (#1, #2, #3 and predicted like count)\n",
        "combined = layers.concatenate([x1.output, x2.output, x3.output, x4.output])\n",
        "y2 = layers.Flatten()(combined)\n",
        "y2 = layers.Dense(1, activation=\"linear\")(y2)\n",
        "#Define the model\n",
        "y2_model = Model(inputs=[x1.input, x2.input, x3.input, x4.input], outputs=y2)"
      ],
      "metadata": {
        "id": "udh4LzTA1xcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y2_model.summary()"
      ],
      "metadata": {
        "id": "kCViDjci14N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(y2_model, to_file='Cnn + Metadata.png')"
      ],
      "metadata": {
        "id": "y8622eJj17p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. Data Preparation for 2nd model"
      ],
      "metadata": {
        "id": "wbkX2IMRE_y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reconfirm shuffled_df\n",
        "shuffled_df = merged_df.sample(frac=1, random_state=0)\n",
        "shuffled_df"
      ],
      "metadata": {
        "id": "Xc-kVogR-6Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get predicted like count for all samples by applying model 1\n",
        "(X_pic, X_stats, X_sliced_video_images), (y1, y2) = get_X_y(shuffled_df)\n",
        "like_count_prediction = y1_model.predict([X_pic, X_stats, X_sliced_video_images])"
      ],
      "metadata": {
        "id": "AMqWwmU0HofO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rest index to avoid errors in pd.concat\n",
        "shuffled_df = shuffled_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "J5SndYirEEGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding predicted like counts to shuffled_df\n",
        "shuffled_df_with_predicted_like_count = pd.concat([shuffled_df, pd.DataFrame(like_count_prediction)], axis=1) #Index is reset\n",
        "shuffled_df_with_predicted_like_count = shuffled_df_with_predicted_like_count.drop(['like_count'], axis=1)\n",
        "shuffled_df_with_predicted_like_count.columns = ['display_id', 'view_count', 'NPZ_Files', 'like_count'] #'like_count' is predicted like count\n",
        "shuffled_df_with_predicted_like_count"
      ],
      "metadata": {
        "id": "cGV0xZJC69Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to get X_pic, X_stats, and y from a DataFrame\n",
        "def get_X_y2(df):\n",
        "  X_pic, X_metadata, X_sliced_video_images = [], [], []\n",
        "  y1 = []\n",
        "  y2 = []\n",
        "  k = 0 #counter\n",
        "  df = df.reset_index(drop=True)\n",
        "  for name in df['NPZ_Files']:\n",
        "    loaded_npz = np.load(name)\n",
        "    pic = loaded_npz['pic']\n",
        "    stats = loaded_npz['stats']\n",
        "    sliced_video_images = loaded_npz['sliced_video_images']\n",
        "    X_pic.append(pic)\n",
        "    X_metadata.append(stats)\n",
        "    X_sliced_video_images.append(sliced_video_images)\n",
        "    y1.append([df['like_count'][k]]) #Predicted like count instead of given like count as users cannot get like count upfront\n",
        "    y2.append([loaded_npz['view_count']])    \n",
        "    print(k)\n",
        "    k += 1\n",
        "  X_pic, X_metadata, X_sliced_video_images = np.array(X_pic), np.array(X_metadata), np.array(X_sliced_video_images)\n",
        "  y1 = np.array(y1)\n",
        "  y2 = np.array(y2)\n",
        "  return (X_pic, X_metadata, X_sliced_video_images), (y1, y2)"
      ],
      "metadata": {
        "id": "R0li9XwZ9WBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df2, val_df2, test_df2 = shuffled_df_with_predicted_like_count[:1000], shuffled_df_with_predicted_like_count[1000:1100], shuffled_df_with_predicted_like_count[1100:shuffled_df.shape[0]]\n",
        "print(len(train_df2),len(val_df2),len(test_df2))\n",
        "# now the data is ready in these dframes\n",
        "\n",
        "#Loading the data may take 10 mins\n",
        "(X_train_pic, X_train_stats, X_train_sliced_video_images), (y1_train, y2_train) = get_X_y2(train_df2) #Train data\n",
        "(X_val_pic, X_val_stats, X_val_sliced_video_images), (y1_val, y2_val) = get_X_y2(val_df2) #Validation data\n",
        "(X_test_pic, X_test_stats, X_test_sliced_video_images), (y1_test, y2_test) = get_X_y2(test_df2) #Test data"
      ],
      "metadata": {
        "id": "7-0eulxC8Kgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. Model Training (2nd model to predict view count)"
      ],
      "metadata": {
        "id": "kijKlJA4FIg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y2_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error','mean_squared_error'])"
      ],
      "metadata": {
        "id": "1eVr5nd18CLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model saving callback and train for 10 epochs (connect to GPU runtime!!)\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "cp = ModelCheckpoint('model/', save_best_only=True)\n",
        "tf.get_logger().setLevel('ERROR') #do not show warning due to data augumentation\n",
        "r2 = y2_model.fit(x=[X_train_pic, X_train_stats, X_train_sliced_video_images, y1_train], y=y2_train, \n",
        "              validation_data=([X_val_pic, X_val_stats, X_val_sliced_video_images, y1_val], y2_val), epochs=10, callbacks=[cp])"
      ],
      "metadata": {
        "id": "hMp-61sYvl56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(r2.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(r2.history['mean_absolute_error'])\n",
        "#plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(r2.history['loss'])\n",
        "plt.plot(r2.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "#plt.ylim(0,0.5e9)\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MEfg-n1eNAZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. Test Prediction and Result Evaluation  (2nd model to predict view count)"
      ],
      "metadata": {
        "id": "ZZ0qPFSgFPGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict view count by using thubmnails, metadata, sliced video images and predicted like count\n",
        "test_predictions_view_count = y2_model.predict([X_test_pic, X_test_stats, X_test_sliced_video_images, y2_test])\n",
        "test_predictions_view_count #predicted view count"
      ],
      "metadata": {
        "id": "9PPxDWWiNK2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y2_test #view count data"
      ],
      "metadata": {
        "id": "uJUGUtq6N4E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge view count data and predicted view count\n",
        "y2_test_df = pd.DataFrame(y2_test)\n",
        "test_predictions_view_count_df = pd.DataFrame(test_predictions_view_count)\n",
        "\n",
        "y2_test_df.columns = ['view_count']\n",
        "test_predictions_view_count_df.columns = ['predicted_view_count']\n",
        "\n",
        "test_result_view_count = pd.concat([y2_test_df,test_predictions_view_count_df],axis=1)\n",
        "test_result_view_count = test_result_view_count.sort_values(by='view_count',axis=0,ascending=False)"
      ],
      "metadata": {
        "id": "AMH8SHSLOXCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparison with average\n",
        "avg = merged_df['view_count'].mean()\n",
        "plt.ylim(0,50000)\n",
        "plt.xlabel(\"Sample (descending order by view count)\")\n",
        "plt.ylabel(\"View counts\")\n",
        "plt.title(\"Comparison between actual and predicted view count\")\n",
        "plt.hlines(avg,0,test_result_view_count.shape[0],color='g',label='average view count in all data')\n",
        "plt.plot(np.arange(0,test_result_view_count.shape[0],1),test_result_view_count['view_count'],color='b',label='actual view count')\n",
        "plt.plot(np.arange(0,test_result_view_count.shape[0],1),test_result_view_count['predicted_view_count'],color='r',label='predicted view count')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "StgZn4KyOsHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate quantile values\n",
        "q1 = merged_df['view_count'].quantile(q=0.25)\n",
        "q2 = merged_df['view_count'].quantile(q=0.5)\n",
        "q3 = merged_df['view_count'].quantile(q=0.75)\n",
        "avg = merged_df['view_count'].mean()\n",
        "\n",
        "view_count_category_avg = []\n",
        "predicted_view_count_category_avg = []\n",
        "avg_category_result = []\n",
        "view_count_category_quantile = []\n",
        "predicted_view_count_category_quantile = []\n",
        "quantile_category_result = []\n",
        "\n",
        "for i in range(test_result_view_count.shape[0]):\n",
        "  #View count categorisation by average\n",
        "  if test_result_view_count['view_count'][i] > avg: view_count_category_avg.append('above_average')\n",
        "  else: view_count_category_avg.append('below_average')\n",
        "\n",
        "  if test_result_view_count['predicted_view_count'][i] > avg: predicted_view_count_category_avg.append('above_average')\n",
        "  else: predicted_view_count_category_avg.append('below_average')\n",
        "\n",
        "  if view_count_category_avg[i] == predicted_view_count_category_avg[i]: avg_category_result.append(True)\n",
        "  else: avg_category_result.append(False)\n",
        "\n",
        "  #View count categorisation by quantile\n",
        "  if test_result_view_count['view_count'][i] > q3: view_count_category_quantile.append('1) Top 25%')\n",
        "  elif test_result_view_count['view_count'][i] > q2: view_count_category_quantile.append('2) Top 25-50%')\n",
        "  elif test_result_view_count['view_count'][i] > q1: view_count_category_quantile.append('3) Lower 25-50%')\n",
        "  else: view_count_category_quantile.append('4) Lowest 25%')\n",
        "\n",
        "  if test_result_view_count['predicted_view_count'][i] > q3: predicted_view_count_category_quantile.append('1) Top 25%')\n",
        "  elif test_result_view_count['predicted_view_count'][i] > q2: predicted_view_count_category_quantile.append('2) Top 25-50%')\n",
        "  elif test_result_view_count['predicted_view_count'][i] > q1: predicted_view_count_category_quantile.append('3) Lower 25-50%')\n",
        "  else: predicted_view_count_category_quantile.append('4) Lowest 25%')\n",
        "\n",
        "  if view_count_category_quantile[i] == predicted_view_count_category_quantile[i]: quantile_category_result.append(True)\n",
        "  else: quantile_category_result.append(False)\n",
        "\n",
        "view_count_category_avg = pd.DataFrame(view_count_category_avg)\n",
        "predicted_view_count_category_avg = pd.DataFrame(predicted_view_count_category_avg)\n",
        "avg_category_result = pd.DataFrame(avg_category_result)\n",
        "view_count_category_quantile = pd.DataFrame(view_count_category_quantile)\n",
        "predicted_view_count_category_quantile = pd.DataFrame(predicted_view_count_category_quantile)\n",
        "quantile_category_result = pd.DataFrame(quantile_category_result)"
      ],
      "metadata": {
        "id": "pN6Ai_q6O63d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(view_count_category_avg.value_counts())\n",
        "print('\\n')\n",
        "print(predicted_view_count_category_avg.value_counts())\n",
        "print('\\n')\n",
        "print(avg_category_result.value_counts())\n",
        "print('\\n')\n",
        "print(view_count_category_quantile.value_counts())\n",
        "print('\\n')\n",
        "print(predicted_view_count_category_quantile.value_counts())\n",
        "print('\\n')\n",
        "print(quantile_category_result.value_counts())"
      ],
      "metadata": {
        "id": "D92sfj-2QoJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_result = pd.concat([view_count_category_avg,\n",
        "                             predicted_view_count_category_avg,\n",
        "                             avg_category_result,\n",
        "                             view_count_category_quantile,\n",
        "                             predicted_view_count_category_quantile,\n",
        "                             quantile_category_result],axis=1)\n",
        "category_result.columns = [\"view_count_category_avg\",\n",
        "                           \"predicted_view_count_category_avg\",\n",
        "                           \"avg_category_result\",\n",
        "                           \"view_count_category_quantile\",\n",
        "                           \"predicted_view_count_category_quantile\",\n",
        "                           \"quantile_category_result\"]"
      ],
      "metadata": {
        "id": "C8FD9jIzQzZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_result"
      ],
      "metadata": {
        "id": "4w3sleI-Q81_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix for 2 categories (above_average, below_average)\n",
        "confusion_mat_2cat_view = category_result.pivot_table('avg_category_result', index='view_count_category_avg',columns='predicted_view_count_category_avg', aggfunc='count')\n",
        "print(confusion_mat_2cat_view)\n",
        "\n",
        "#metrics calculation\n",
        "accuracy_view = (confusion_mat_2cat_view['above_average']['above_average']+confusion_mat_2cat_view['below_average']['below_average'])/confusion_mat_2cat_view.sum().sum()\n",
        "recall_above_abv_avg_view = (confusion_mat_2cat_view['above_average']['above_average'])/confusion_mat_2cat_view.loc['above_average'].sum()\n",
        "precision_above_abv_avg_view = (confusion_mat_2cat_view['above_average']['above_average'])/confusion_mat_2cat_view['above_average'].sum()\n",
        "f1_score_abv_avg_view = 2/(1/recall_above_abv_avg_view+1/precision_above_abv_avg_view)\n",
        "\n",
        "recall_above_blw_avg_view = (confusion_mat_2cat_view['below_average']['below_average'])/confusion_mat_2cat_view.loc['below_average'].sum()\n",
        "precision_above_blw_avg_view = (confusion_mat_2cat_view['below_average']['below_average'])/confusion_mat_2cat_view['below_average'].sum()\n",
        "f1_score_blw_avg_view = 2/(1/recall_above_blw_avg_view+1/precision_above_blw_avg_view)\n",
        "\n",
        "#result\n",
        "print('\\n')\n",
        "print(\"Accuracy is \"+str(round(accuracy_view,2)))\n",
        "print('\\n')\n",
        "print(\"Recall of 'above_average' is \"+str(round(recall_above_abv_avg_view,2)))\n",
        "print(\"Precision of 'above_average' is \"+str(round(precision_above_abv_avg_view,2)))\n",
        "print(\"F1 score of 'above_average' is \"+str(round(f1_score_abv_avg_view,2)))\n",
        "print('\\n')\n",
        "print(\"Recall of 'below_average' is \"+str(round(recall_above_blw_avg_view,2)))\n",
        "print(\"Precision of 'below_average' is \"+str(round(precision_above_blw_avg_view,2)))\n",
        "print(\"F1 score of 'below_average' is \"+str(round(f1_score_blw_avg_view,2)))"
      ],
      "metadata": {
        "id": "nhVgXsEiQ-3k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}